{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!export PYDEVD_DISABLE_FILE_VALIDATION=1"
      ],
      "metadata": {
        "id": "76WGW0njzsaj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn5azmHsxxD5",
        "outputId": "cbcd5138-3e3a-4e2d-e289-4e0d881a2bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Clotex_api'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 159 (delta 49), reused 146 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (159/159), 1.29 MiB | 26.89 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "/content/Clotex_api/backend\n",
            "Using CPython 3.12.12 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m111 packages\u001b[0m \u001b[2min 29ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m103 packages\u001b[0m \u001b[2min 1m 39s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m103 packages\u001b[0m \u001b[2min 1.26s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-doc\u001b[0m\u001b[2m==0.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mastunparse\u001b[0m\u001b[2m==1.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.120.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.9.23\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgast\u001b[0m\u001b[2m==0.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgoogle-pasta\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh5py\u001b[0m\u001b[2m==3.15.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mimageio\u001b[0m\u001b[2m==2.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkeras\u001b[0m\u001b[2m==3.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlazy-loader\u001b[0m\u001b[2m==0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlibclang\u001b[0m\u001b[2m==18.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mml-dtypes\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnamex\u001b[0m\u001b[2m==0.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvcc-cu12\u001b[0m\u001b[2m==12.9.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopt-einsum\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptree\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.10.23\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-image\u001b[0m\u001b[2m==0.25.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.49.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard-data-server\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorflow\u001b[0m\u001b[2m==2.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtermcolor\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtf-keras\u001b[0m\u001b[2m==2.20.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtifffile\u001b[0m\u001b[2m==2025.10.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.38.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            "/content/Clotex_api\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/feed7362/Clotex_api\n",
        "%cd Clotex_api/backend\n",
        "!uv sync\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask requests pyngrok\n",
        "\n",
        "import subprocess, time, threading\n",
        "from flask import Flask, send_from_directory, request\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ---------- 1Ô∏è‚É£ Start FastAPI backend ----------\n",
        "backend_process = subprocess.Popen([\n",
        "    \"uv\", \"run\", \"uvicorn\", \"main:app\",\n",
        "    \"--host\", \"0.0.0.0\", \"--port\", \"8000\"\n",
        "], cwd=\"./backend\",     stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1)\n",
        "\n",
        "time.sleep(150)  # Give backend time to boot\n",
        "def stream_backend_logs(proc):\n",
        "    print(\"üìú Backend logs (live):\")\n",
        "    for line in iter(proc.stdout.readline, ''):\n",
        "        if not line:\n",
        "            break\n",
        "        print(\"üß†\", line.strip())\n",
        "    print(\"‚ö†Ô∏è Backend log stream ended.\")\n",
        "threading.Thread(target=stream_backend_logs, daemon=True, args=(backend_process,)).start()\n",
        "\n",
        "# ---------- 2Ô∏è‚É£ Flask static + API proxy ----------\n",
        "FRONTEND_DIR = \"./frontend\"\n",
        "BACKEND_URL = \"http://127.0.0.1:8000\"\n",
        "\n",
        "app = Flask(__name__, static_folder=FRONTEND_DIR)\n",
        "\n",
        "\n",
        "@app.route(\"/api/<path:path>\", methods=[\"GET\",\"POST\",\"PUT\",\"DELETE\"])\n",
        "def api_proxy(path):\n",
        "    url = f\"{BACKEND_URL}/api/{path}\"\n",
        "    resp = requests.request(\n",
        "        method=request.method,\n",
        "        url=url,\n",
        "        headers={k: v for k, v in request.headers.items() if k.lower() != \"host\"},\n",
        "        data=request.get_data(),\n",
        "        cookies=request.cookies,\n",
        "        allow_redirects=False)\n",
        "    return (resp.content, resp.status_code, resp.headers.items())\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return send_from_directory(FRONTEND_DIR, \"index.html\")\n",
        "\n",
        "@app.route(\"/<path:path>\")\n",
        "def static_proxy(path):\n",
        "    return send_from_directory(FRONTEND_DIR, path)\n",
        "\n",
        "# ---------- 3Ô∏è‚É£ Run Flask in background ----------\n",
        "def run_flask():\n",
        "    app.run(host=\"0.0.0.0\", port=3000, debug=False, use_reloader=False)\n",
        "\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "time.sleep(3)\n",
        "\n",
        "# ---------- 4Ô∏è‚É£ Expose via ngrok ----------\n",
        "ngrok.set_auth_token(\"353y4cZpz3P1rrhwPjMxpQ0pDoV_3Dh8JvYy5EDxyFLuVzRuv\")\n",
        "public_url = ngrok.connect(3000, bind_tls=True)\n",
        "print(\"üöÄ Public URL:\", public_url)\n",
        "print(\"‚úÖ Flask frontend + FastAPI backend are both live\")\n",
        "\n",
        "try:\n",
        "    resp = requests.get(f\"{BACKEND_URL}/api/health/live\", timeout=5)\n",
        "    print(\"Backend health:\", resp.status_code, resp.text)\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Backend not reachable:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVS0NekOzl3r",
        "outputId": "4e979c6d-8f2f-4a32-c754-427b37b9f5f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.1\n",
            "üìú Backend logs (live):\n",
            "üß† 2025-11-05 15:15:21.189927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "üß† To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "üß† INFO:     Started server process [3100]\n",
            "üß† INFO:     Waiting for application startup.\n",
            "üß† 2025-11-05 15:15:35,424 [INFO] [root] üß† Initializing application lifespan context...\n",
            "üß† /content/Clotex_api/backend/.venv/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "üß† _C._set_float32_matmul_precision(precision)\n",
            "üß† üßπ Cleared old debug_results at /content/Clotex_api/backend/debug_results\n",
            "üß† üßπ GPU memory cache cleared.\n",
            "üß† 2025-11-05 15:15:36,287 [INFO] [root] ‚úÖ Cleaned up temporary GPU memory and cache\n",
            "üß† 2025-11-05 15:15:36,287 [INFO] [root] ‚öôÔ∏è Loading models in background threads...\n",
            "üß† 2025-11-05 15:15:36,315 [INFO] [image_processing.classify] [classify] Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "üß† 2025-11-05 15:15:36,315 [INFO] [image_processing.classify] ‚úÖ Enabled TensorFlow GPU memory growth\n",
            "üß† WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "üß† I0000 00:00:1762355736.327232    3269 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "üß† /content/Clotex_api/backend/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 90 variables whereas the saved optimizer has 94 variables.\n",
            "üß† saveable.load_own_variables(weights_store.get(inner_path))\n",
            "üß† 2025-11-05 15:15:39,954 [INFO] [image_processing.classify] ‚úÖ Model loaded from ./models/image_classifier.keras in 3.64s\n",
            "üß† 2025-11-05 15:15:41.466627: I external/local_xla/xla/service/service.cc:163] XLA service 0x7c137c63c340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "üß† 2025-11-05 15:15:41.466645: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "üß† 2025-11-05 15:15:41.615449: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "üß† 2025-11-05 15:15:42.542513: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
            "üß† 2025-11-05 15:15:43.457088: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,128,128,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,257,257,4]{3,2,1,0}, f16[32,3,3,4]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.457123: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,128,128,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,257,257,4]{3,2,1,0}, f16[32,3,3,4]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.492126: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,128,128,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,257,257,4]{3,2,1,0}, f16[32,3,3,4]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.728731: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,128,128,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,128,128,32]{3,2,1,0}, f16[16,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.728768: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,128,128,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,128,128,32]{3,2,1,0}, f16[16,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.739607: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,128,128,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,128,128,32]{3,2,1,0}, f16[16,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.833812: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,129,129,16]{3,2,1,0}, f16[64,3,3,16]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.851972: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,129,129,16]{3,2,1,0}, f16[64,3,3,16]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:43.858061: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,64,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,129,129,16]{3,2,1,0}, f16[64,3,3,16]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.131047: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,64]{3,2,1,0}, f16[32,1,1,64]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.133241: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,64]{3,2,1,0}, f16[32,1,1,64]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.137414: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,64]{3,2,1,0}, f16[32,1,1,64]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.209885: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,64,64,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.224454: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,64,64,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.239089: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,64,64,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.309981: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,128]{3,2,1,0}, f16[32,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.323440: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,128]{3,2,1,0}, f16[32,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.326898: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,64,64,128]{3,2,1,0}, f16[32,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.373224: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,32,32,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,65,65,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.384854: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,32,32,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,65,65,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.396723: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,32,32,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,65,65,32]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.526229: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,128]{3,2,1,0}, f16[48,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.527871: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,128]{3,2,1,0}, f16[48,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.535983: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,128]{3,2,1,0}, f16[48,1,1,128]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.598288: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,32,32,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,48]{3,2,1,0}, f16[192,3,3,48]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.599968: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,32,32,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,48]{3,2,1,0}, f16[192,3,3,48]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.676797: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,192]{3,2,1,0}, f16[48,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.676827: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,192]{3,2,1,0}, f16[48,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.689833: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,32,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,192]{3,2,1,0}, f16[48,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.746000: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,32,32,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,48]{3,2,1,0}, f16[192,1,1,48]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.749297: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,32,32,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,48]{3,2,1,0}, f16[192,1,1,48]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:44.759001: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,32,32,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,32,32,48]{3,2,1,0}, f16[192,1,1,48]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.322808: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,192]{3,2,1,0}, f16[96,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.322850: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,192]{3,2,1,0}, f16[96,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.336420: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,192]{3,2,1,0}, f16[96,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.370714: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,384]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[384,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.372528: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,384]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[384,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:46.386364: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,384]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[384,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.737480: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,384]{3,2,1,0}, f16[96,1,1,384]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.737515: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,384]{3,2,1,0}, f16[96,1,1,384]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.750784: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,384]{3,2,1,0}, f16[96,1,1,384]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.776142: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,576]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[576,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.777860: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,576]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[576,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:47.791186: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,576]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,96]{3,2,1,0}, f16[576,1,1,96]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.672254: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,576]{3,2,1,0}, f16[112,1,1,576]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.672289: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,576]{3,2,1,0}, f16[112,1,1,576]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.685953: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,576]{3,2,1,0}, f16[112,1,1,576]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.708698: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,672]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,112]{3,2,1,0}, f16[672,1,1,112]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.710317: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,672]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,112]{3,2,1,0}, f16[672,1,1,112]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:48.723699: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,672]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,112]{3,2,1,0}, f16[672,1,1,112]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:49.605122: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,672]{3,2,1,0}, f16[112,1,1,672]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:49.605160: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,672]{3,2,1,0}, f16[112,1,1,672]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:49.618390: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,16,16,112]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,16,16,672]{3,2,1,0}, f16[112,1,1,672]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:50.314929: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,8,8,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,672]{3,2,1,0}, f16[192,1,1,672]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:50.314962: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,8,8,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,672]{3,2,1,0}, f16[192,1,1,672]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:50.349557: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,8,8,1152]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1152,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:50.354439: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,8,8,1152]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1152,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:50.361117: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,8,8,1152]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1152,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.242535: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,8,8,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,1152]{3,2,1,0}, f16[192,1,1,1152]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.247559: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,8,8,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,1152]{3,2,1,0}, f16[192,1,1,1152]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.260947: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,8,8,192]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,1152]{3,2,1,0}, f16[192,1,1,1152]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.281599: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=0,k4=1,k5=3,k6=3,k7=2} for conv (f16[1,8,8,1280]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1280,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.286515: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=3,k4=2,k5=3,k6=3,k7=2} for conv (f16[1,8,8,1280]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1280,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† 2025-11-05 15:15:51.292808: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k2=4,k4=1,k5=4,k6=3,k7=2} for conv (f16[1,8,8,1280]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,8,8,192]{3,2,1,0}, f16[1280,1,1,192]{3,2,1,0}), window={size=1x1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
            "üß† I0000 00:00:1762355755.326318    3269 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "üß† 2025-11-05 15:16:01,259 [INFO] [image_processing.classify] üî• Model warm-up completed in 21.30s\n",
            "üß† 2025-11-05 15:16:01,259 [INFO] [root] ‚úÖ TensorFlow model loaded & warmed up\n",
            "üß† 2025-11-05 15:16:01,260 [INFO] [image_processing.segment] [segment] Loading SAM2 generator (syscv-community/sam-hq-vit-huge)...\n",
            "üß† Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "üß† Device set to use cuda:0\n",
            "üß† 2025-11-05 15:16:53,228 [INFO] [image_processing.segment] ‚úÖ SAM2 generator loaded on: cuda:0 in 51.97s\n",
            "üß† 2025-11-05 15:16:53,229 [INFO] [root] ‚úÖ SAM2 generator initialized\n",
            "üß† 2025-11-05 15:16:53,229 [INFO] [image_processing.upscale] [upscale] Loading ONNX model from: ./models/modelx4.ort\n",
            "üß† /content/Clotex_api/backend/.venv/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "üß† warnings.warn(\n",
            "üß† 2025-11-05 15:16:53,344 [INFO] [image_processing.upscale] [upscale] Available providers: ['CPUExecutionProvider']\n",
            "üß† 2025-11-05 15:16:53,404 [INFO] [image_processing.upscale] [upscale] üî• Model warm-up complete in 0.17s (CPUExecutionProvider)\n",
            "üß† 2025-11-05 15:16:53,404 [INFO] [root] ‚úÖ ONNX upscaler warmed up\n",
            "üß† 2025-11-05 15:16:53,404 [INFO] [root] üöÄ Startup complete in 77.98s ‚Äî all models ready.\n",
            "üß† INFO:     Application startup complete.\n",
            "üß† INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:3000\n",
            " * Running on http://172.28.0.12:3000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Public URL: NgrokTunnel: \"https://hirstie-brianne-retributively.ngrok-free.dev\" -> \"http://localhost:3000\"\n",
            "‚úÖ Flask frontend + FastAPI backend are both live\n",
            "Backend health: 200 {\"status\":\"ok\",\"details\":null}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()\n",
        "!lsof -i:8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31vdi-z63M6D",
        "outputId": "0613a3b5-49f0-43fc-b438-9d39718789bc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3  178 root   57u  IPv4 289109      0t0  TCP localhost:46814->localhost:8000 (CLOSE_WAIT)\n",
            "uvicorn 9759 root   53u  IPv4 276003      0t0  TCP *:8000 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f uvicorn\n"
      ],
      "metadata": {
        "id": "t173VSb5e8v9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://127.0.0.1:8000/api/health/live\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0TXMSImM2Ni",
        "outputId": "c453b0ea-7fef-41dc-c84e-e20f7fd5410a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [05/Nov/2025 15:18:03] \"POST /api/raw_image/process HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† 2025-11-05 15:18:03,016 [INFO] [image_processing.segment] [segment] SAM2 returned 2 mask(s)\n",
            "üß† 2025-11-05 15:18:03,036 [INFO] [debug.save] [debug.save] Saved mask_1 ‚Üí debug_results/seg/mask_1.png\n",
            "üß† 2025-11-05 15:18:03,054 [INFO] [debug.save] [debug.save] Saved mask_2 ‚Üí debug_results/seg/mask_2.png\n",
            "üß† 2025-11-05 15:18:03,054 [INFO] [image_processing.segment] ‚úÖ Created 2 segmented images in 9.89s\n",
            "üß† 2025-11-05 15:18:03,054 [INFO] [image_processing] [12.jpg] Step:segment ok\n",
            "üß† 2025-11-05 15:18:03,054 [INFO] [image_processing] [12.jpg] Step:classify started\n",
            "üß† 2025-11-05 15:18:03,054 [INFO] [image_processing.classify] [classify] Starting classification on 2 mask(s), threshold=0.5\n",
            "üß† 2025-11-05 15:18:03,103 [INFO] [image_processing.classify] [classify] Mask 1: score=0.1783, time=0.049s\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing.classify] [classify] Mask 2: score=0.1006, time=0.013s\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing.classify] [classify] Completed: 0 / 2 mask(s) retained\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing] [12.jpg] Step:classify ok\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing] [12.jpg] Step:upscale started\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing.upscale] [upscale] Starting upscaling using CPUExecutionProvider\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing.upscale] [upscale] Finished 0 image(s)\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing] [12.jpg] Step:upscale ok\n",
            "üß† 2025-11-05 15:18:03,116 [INFO] [image_processing] [12.jpg] Step:color_separate started\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing.color_layers] [color_layers_batch] Processing 0 image(s)\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing.color_layers] [color_layers_batch] Total layers: 0\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing] [12.jpg] Step:color_separate ok (layers=0)\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing] [12.jpg] Step:add_anchors started\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing.anchors] [Anchors] Processing 0 layer(s)\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing.anchors] [Anchors] Finished 0 layer(s)\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing] [12.jpg] Step:add_anchors ok\n",
            "üß† 2025-11-05 15:18:03,117 [INFO] [image_processing] [12.jpg] completed successfully\n",
            "{\"status\":\"ok\",\"details\":null}"
          ]
        }
      ]
    }
  ]
}